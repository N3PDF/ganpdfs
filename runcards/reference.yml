#############################################################################################
# Input PDF                                                                                 #
#############################################################################################
pdf: 210219-02-rs-nnpdf40-1000

#############################################################################################
# PDF Grids:                                                                                #
# ---------                                                                                 #
# * Inittial scale q (in GeV)                                                               #
# * Options for x-grid:                                                                     #
#   - custom: Custom GANs xgrid as defined in the Module                                    #
#   - lhapdf: Use the same xgrid as in the input PDF                                        #
#############################################################################################
q          : 1.65                                    # Initial q0 value (in GeV)
x_grid     : standard                                # x-grid format. Options: standard, custom, lhapdf
nb_xpoints : 500                                     # Size of the x-grid

#############################################################################################
# GAN setup:                                                                                #
# ---------                                                                                 #
# * Options for architecture:                                                               #
#   - dnn : Deep Neural Network                                                             #
#   - dcnn: Deep Convolutional Neural Network                                               #
#############################################################################################
use_saved_model       : False                        # Skip training and use pre-trained generator model
                                                     # All the parameters below will be skipped is set to TRUE

architecture          : dnn                          # Architecture model. Options: dnn, dcnn

gan_parameters:
  optimizer:
    optimizer_name    : Adam                         # options: SGD, Adam, RMSprop, Adadelta
    learning_rate     : 0.00005                      # Learning rate for the optimizer class
  loss                : wasserstein                  # options: all tf.keras losses + wasserstein

gen_parameters:
  structure           : custom                       # Optios: `custom` for custom latent space, `standard` for usual noise
  size_networks       : 1                            # number of hidden layers
  kernel_initializer  : glorot_uniform               # list of initializer classes: https://keras.io/api/layers/initializers/
  activation          : leakyrelu                    # options: relu, leakyrelu, elu
  use_bias            : False                        # if True add biases to the Layers

disc_parameters:
  size_networks       : 1                            # number of hidden layers
  number_nodes        : 250                          # number of nodes in the first layer
  use_bias            : False                        # if True add biases to the Layers
  kernel_initializer  : glorot_uniform               # list of initializer classes: https://keras.io/api/layers/initializers/
  weights_constraints : 1                            # Constrain weights values
  gp_weight           : 10                           # Gradient Penalty weight
  gp_loss             : 1.0                          # Gradient Penalty loss. Set to zero if weights constraints is 0.01
  optimizer:
    optimizer_name    : RMSprop                      # options: SGD, Adam, RMSprop, Adadelta
    learning_rate     : 0.0005                       # learning rate for the optimizer class
  loss                : wasserstein                  # options: all tf.keras losses + wasserstein
  activation          : relu                         # options: relu, leakyrelu, elu

#############################################################################################
# Training Setup:                                                                           #
# --------------                                                                            #
# * batch size                                                                              #
# * {i}_steps: number of steps to train a {i}={generator, discriminator/critic} at each     #
#   iteration.                                                                              #
#############################################################################################
nd_steps   : 4                                       # Number of steps to train the Discriminator for one training run
ng_steps   : 1                                       # Number of steps to train the Generator for one training run
batch_size : 50                                      # Batch size per epoch in terms of percentage
epochs     : 1000                                    # Number of epochs
